= Analizador Lexico
:Author:    Touceda, Tomas ; Garay, Iñaki
:Date:      30/08/2011

== Instrucciones
== Decisiones de diseño

== Alfabeto de entrada

El alfabeto de entrada son todos los carácteres de la tabla ASCII.

== Definición de Tokens

*Aclaraciones:*
1. Para evitar ambiguedades, las expresiones regulares se expresaron utilizando la sintaxis válidad para JLex.
2. Las entradas que no cuentan con ejemplos tienen un unico representante, igual a la expresion regular con la cual coincide.

|===
[options="header"]
|Token          |Expresion regular                    |Ejemplos
|IDENTIFIER     |[a-zA-Z_\$][a-zA-Z_\$0-9]*           |hola
|SEPARATOR      |[ \t\n\r]                            |
|INT_LITERAL    |(0|[1-9]([0-9])*)                    |42
|CHAR_LITERAL   |((\'[^('\\)\')|(\'[\\\\|\\'|\\\"|\\n]\')) |'q'
|STRING_LITERAL |(\"\"|\"[^(\"\\)|[\\\\|\\'|\\\"|\\n]\") |"hola"
|SCOLON         |;                                    |
|BRACE_OPEN     |\{                                   |
|BRACE_CLOSE    |\}                                   |
|PAREN_OPEN     |\)                                   |
|PAREN_CLOSE    |\(                                   |
|CLASS          |class                                |
|EXTENDS        |extends                              |
|PUBLIC         |public                               |
|PROTECTED      |protected                            |
|STATIC         |static                               |
|THIS           |this                                 |
|SUPER          |super                                |
|VOID_TYPE      |void                                 |
|BOOLEAN_TYPE   |bool                                 |
|INT_TYPE       |int                                  |
|CHAR_TYPE      |char                                 |
|IF             |if                                   |
|THEN           |then                                 |
|ELSE           |else                                 |
|WHILE          |while                                |
|RETURN         |return                               |
|TRUE           |true                                 |
|FALSE          |false                                |
|NULL           |null                                 |
|NEW            |new                                  |
|ASSIGNMENT     |=                                    |
|CONDITIONAL_AND|&&                                   |
|EQUALS         |==                                   |
|NOT_EQUALS     |!=                                   |
|LT             |<                                    |
|GT             |>                                    |
|LT_EQ          |<=                                   |
|GT_EQ          |>=                                   |
|ADD            |+                                    |
|SUB            |-                                    |
|MUL            |*                                    |
|DIV            |\/                                   |
|MOD            |%                                    |
|NOT            |!                                    |
|ACCESSOR       |.                                    |
|EOF            |<EOF>                                |
|===

== Detalles de implementación

Para implementar el analizador léxico se realizó la especificación de la máquina de estados basándose en las expresiones regulares definidas en la sección anterior, para luego representarlo en código Python.

De esta forma, la clase principal utilizada es la llamada State. Esta no es más que una abstracción de la idea es estado de un autómata finito, que cuenta con una serie de funciones de checkeo para determinar si se debe pasar a un siguiente estado o no, y alrededor de esta idea se estableció la lógica para la detección de ciertos errores léxicos.

En el archivo states.py se encuentra la definición de esta clase mencionada, y la del autómata finito reconocedor utilizado.

Para representar a los tokens se armaron dos clases: TokenType y Token. TokenType, definida en constants.py, es una abstracción sobre los distintos tipos de tokens reconocidos y especificados en la sección anterior. Token, definida en lexor.py, abstrae un token instanciado según el análisis del archivo de código fuente en cuestión.

Por último, Lexor es la clase que representa al analizador léxico propiamente. Este implementa el método get_token() que devuelve secuencialmente todos los tokens reconocidos en un dado archivo que contiene código en MiniJava. Esta clase se encuentra definida en lexor.py.

Para el manejo de errores, se creó el tipo de excepción LexicalError dentro del archivo errors.py.

== Manejo de errores

El analizador léxico reconoce los siguientes tipos de errores:
1. Comentario del tipo /* */ que no esté propiamente cerrado.
2. Informa de tokens no reconocidos.
